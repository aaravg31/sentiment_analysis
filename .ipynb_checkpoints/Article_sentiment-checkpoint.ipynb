{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e49b28e-8790-4971-af06-a7141536b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newsapi-python in /Users/aarav/Documents/venv/lib/python3.12/site-packages (0.2.7)\n",
      "Requirement already satisfied: requests<3.0.0 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from newsapi-python) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from requests<3.0.0->newsapi-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from requests<3.0.0->newsapi-python) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from requests<3.0.0->newsapi-python) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from requests<3.0.0->newsapi-python) (2024.6.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: requests in /Users/aarav/Documents/venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from requests) (2024.6.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/aarav/Documents/venv/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install newsapi-python \n",
    "!pip install requests\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b90921b-4b6c-435a-b5bb-520d5de060bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4eaad1-b120-4d9d-8818-dbaaa5f2c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key='57936aa4e13e44d7a4cc8e41f2924cf7')\n",
    "company = 'Infosys'\n",
    "search_query = company + ' shares'\n",
    "articles = newsapi.get_everything(q=search_query, language='en', sort_by='relevancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d972e3-2796-4fe7-8a18-69cf0dda3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_text(text):\n",
    "    return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
    "\n",
    "def sentiment_analysis(df):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    df['Sentiment'] = df['Text'].apply(lambda text: sia.polarity_scores(text)['compound'])\n",
    "    return df\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        return [para.get_text() for para in paragraphs]\n",
    "    else:\n",
    "        print(f\"Failed to retrieve content from {url}\")\n",
    "        return \"\"\n",
    "\n",
    "def make_table(filtered_article_info):\n",
    "    unique_hashes = set()\n",
    "\n",
    "    data = []\n",
    "    for company, url, date, text, text_hash in filtered_article_info:\n",
    "        if text_hash not in unique_hashes:\n",
    "            data.append({'Company': company, 'Date': date, 'URL': url, 'Text': text, 'Text Hash': text_hash})\n",
    "            unique_hashes.add(text_hash)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Company','Date', 'URL', 'Text', 'Text Hash'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = sentiment_analysis(df)\n",
    "    return df  \n",
    "    \n",
    "def store_data(new_df, filename):\n",
    "    if os.path.exists(filename):\n",
    "        existing_df = pd.read_csv(filename)\n",
    "        combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "    else:\n",
    "        combined_df = new_df\n",
    "    \n",
    "    combined_df.to_csv(filename, index=False)\n",
    "\n",
    "def filter_existing_articles(article_info, filename, company):\n",
    "    if os.path.exists(filename):\n",
    "        existing_df = pd.read_csv(filename)\n",
    "        existing_hashes = set(existing_df['Text Hash'])\n",
    "    else:\n",
    "        existing_hashes = set()\n",
    "    \n",
    "    filtered_article_info = []\n",
    "    for url, date in article_info:\n",
    "        paragraphs = get_text_from_url(url)\n",
    "        specific_paragraphs = [para for para in paragraphs if company.lower() in para.lower()]\n",
    "        if specific_paragraphs:\n",
    "            text = '\\n'.join(specific_paragraphs)\n",
    "            text_hash = hash_text(text)\n",
    "            if text_hash not in existing_hashes:\n",
    "                filtered_article_info.append((company, url, date, text, text_hash))\n",
    "                existing_hashes.add(text_hash)\n",
    "    \n",
    "    return filtered_article_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e732ef50-88be-4748-9468-9f9c69906004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve content from https://www.etfdailynews.com/2024/06/22/infosys-nyseinfy-shares-gap-up-to-17-91/\n",
      "Failed to retrieve content from https://www.etfdailynews.com/2024/06/24/wellington-management-group-llp-has-36-96-million-stock-position-in-infosys-limited-nyseinfy/\n",
      "Failed to retrieve content from https://www.etfdailynews.com/2024/06/23/pnc-financial-services-group-inc-acquires-2573-shares-of-infosys-limited-nyseinfy/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/v3y346fs73v85gq618945pxr0000gn/T/ipykernel_81808/1625154436.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "article_info = [(article['url'], article['publishedAt']) for article in articles['articles']]\n",
    "filtered_article_info = filter_existing_articles(article_info, \"stored_sentiments.csv\", company)\n",
    "df = make_table(filtered_article_info)\n",
    "store_data(df,\"stored_sentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24edafc6-0855-4b1a-bb00-89ac0fd4a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)\n",
    "#pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee38b91-3f0c-48c3-860a-c182144076d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
